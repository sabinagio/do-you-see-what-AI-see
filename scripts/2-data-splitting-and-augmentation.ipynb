{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmVTV_tG7ehb"
      },
      "source": [
        "### 2. Data splitting & augmentation\n",
        "\n",
        "Before we train any ML model on our data (ACRIMA dataset), we will first split the data into training & validation sets which can later be augmented using keras' `ImageDataGenerator` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daI8F5zc7ehf"
      },
      "source": [
        "#### 2.1. Train-validation split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aclZd1T7ehg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93mrZ8BC7ehh"
      },
      "outputs": [],
      "source": [
        "# Get the current working directory\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Create new directories to separate the train & validation datasets\n",
        "acrima_dir = os.path.join(current_dir, \"data/acrima-dataset\")\n",
        "new_directories = [\"train\", \"validation\"]\n",
        "new_subdirectories = [\"glaucoma\", \"normal\"]\n",
        "\n",
        "for directory in new_directories:\n",
        "    new_directory_path = os.path.join(acrima_dir, directory)\n",
        "    if os.path.isdir(new_directory_path) == False:\n",
        "        os.makedirs(new_directory_path)\n",
        "\n",
        "    for subdirectory in new_subdirectories:\n",
        "        new_subdirectory_path = os.path.join(new_directory_path, subdirectory)\n",
        "        if os.path.isdir(new_subdirectory_path) == False:\n",
        "            os.makedirs(new_subdirectory_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_Kqq0Ql7ehi"
      },
      "outputs": [],
      "source": [
        "# Create function to split data from glaucoma & normal folders\n",
        "def split_data(source_dir, train_dir, val_dir, split_size):\n",
        "    source_files = os.listdir(source_dir)\n",
        "\n",
        "    # Ensure there are non-empty files\n",
        "    files_to_copy = []\n",
        "\n",
        "    for file_path in source_files:\n",
        "        if os.path.getsize(os.path.join(source_dir, file_path)) > 0:\n",
        "            files_to_copy.append(file_path)\n",
        "\n",
        "    # Shuffle the files in the list for further random selection\n",
        "    files_to_copy = random.sample(files_to_copy, len(files_to_copy))\n",
        "\n",
        "    # Remove previous files from training & validation folders\n",
        "    for file_path in os.listdir(train_dir):\n",
        "        os.remove(os.path.join(train_dir, file_path))\n",
        "\n",
        "    for file_path in os.listdir(val_dir):\n",
        "        os.remove(os.path.join(val_dir, file_path))\n",
        "\n",
        "    # Copy files to the training & validation set\n",
        "    training_size = int(split_size * len(files_to_copy))\n",
        "    for i in range(0, training_size):\n",
        "        source_path = os.path.join(source_dir, files_to_copy[i])\n",
        "        destination_path = os.path.join(train_dir, files_to_copy[i])\n",
        "        shutil.copyfile(source_path, destination_path) \n",
        "\n",
        "    for i in range(training_size, len(files_to_copy)):\n",
        "        source_path = os.path.join(source_dir, files_to_copy[i])\n",
        "        destination_path = os.path.join(val_dir, files_to_copy[i])\n",
        "        shutil.copyfile(source_path, destination_path) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSOYRNan7ehj"
      },
      "outputs": [],
      "source": [
        "# Copy the glaucoma files into the train & validation datasets\n",
        "glaucoma_dir = os.path.join(acrima_dir, \"glaucoma\")\n",
        "glaucoma_train_dir = os.path.join(acrima_dir, \"train/glaucoma\")\n",
        "glaucoma_val_dir = os.path.join(acrima_dir, \"validation/glaucoma\")\n",
        "\n",
        "# We will use a 80% split size initially\n",
        "split_size = 0.8\n",
        "split_data(glaucoma_dir, glaucoma_train_dir, glaucoma_val_dir, split_size=split_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Alvg0uOf7ehk"
      },
      "outputs": [],
      "source": [
        "# Copy the normal files into the train & validation datasets\n",
        "normal_dir = os.path.join(acrima_dir, \"normal\")\n",
        "normal_train_dir = os.path.join(acrima_dir, \"train/normal\")\n",
        "normal_val_dir = os.path.join(acrima_dir, \"validation/normal\")\n",
        "\n",
        "# We'll use the same split size\n",
        "split_data(normal_dir, normal_train_dir, normal_val_dir, split_size=split_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLAV68sx7ehl"
      },
      "source": [
        "#### 2.2. Image augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99VKXvj37ehl"
      },
      "outputs": [],
      "source": [
        "# Create image generators for the training & validation data\n",
        "def image_generators(train_dir, val_dir, train_img_size, val_img_size):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "  train_dir = training data directory\n",
        "  val_dir = validation data directory\n",
        "  train_img_size = the size of the training input images (tuple)\n",
        "  val_img_size = the size of the validation input images (tuple)\n",
        "\n",
        "  Outputs:\n",
        "  train_generator = image generator for training data\n",
        "  val_generator = image generator for validation data\n",
        "  \"\"\"\n",
        "\n",
        "  # Instatiate ImageGenerator & rescale\n",
        "  train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "  val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # Apply the ImageGenerator to the training & validation datasets\n",
        "  train_generator = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                                      batch_size=20,\n",
        "                                                      class_mode='binary',\n",
        "                                                      target_size=train_img_size)\n",
        "\n",
        "  val_generator = val_datagen.flow_from_directory(directory=val_dir,\n",
        "                                                                batch_size=20,\n",
        "                                                                class_mode='binary',\n",
        "                                                                target_size=val_img_size)\n",
        "  \n",
        "  return train_generator, val_generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPaQYOlm7ehm"
      },
      "source": [
        "These functions are also saved in `utils.py` for use in later notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3. Testing data preprocessing\n",
        "\n",
        "Given that evaluation on the full-sized retinal fundus images in the kaggle dataset yielded poor results both with the simple and more complex deep learning models, we will crop the images before re-evaluating them.\n",
        "\n",
        "To do so, we employ a cropping function from [Huazhu Fu's repository](https://github.com/HzFu/MNet_DeepCDR) from a paper on optic disc & cup segmentation[$^{[1]}$](https://arxiv.org/abs/1801.00926), which is based on a U-Net architecture trained to detect the optical disc."
      ],
      "metadata": {
        "id": "HxTt6-hx7kTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JQ3qUKCP__m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "kaggle_dir = \"drive/MyDrive/kaggle_dataset\"\n",
        "g_kaggle_dataset = os.path.join(kaggle_dir, \"glaucoma\")\n",
        "n_kaggle_dataset = os.path.join(kaggle_dir, \"normal\")"
      ],
      "metadata": {
        "id": "0ch6TCY7AQzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code taken and adapted from optic disc / cup segmentation paper\n",
        "from __future__ import print_function\n",
        "\n",
        "from os import path\n",
        "from sys import modules\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pkg_resources import resource_filename\n",
        "from skimage.measure import label, regionprops\n",
        "from skimage.transform import rotate, resize\n",
        "from tensorflow.python.keras.preprocessing import image\n",
        "\n",
        "from cropping_scripts import Model_DiscSeg as DiscModel\n",
        "from cropping_scripts.mnet_utils import BW_img, disc_crop, mk_dir, files_with_ext"
      ],
      "metadata": {
        "id": "_dooasWg-3KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_type = '.png'\n",
        "parent_dir = \"drive/MyDrive\"\n",
        "g_data_img_path = path.abspath(path.join(parent_dir, 'kaggle_dataset', 'glaucoma'))\n",
        "g_data_save_path = mk_dir(path.join(parent_dir, 'training_crop', 'glaucoma'))\n",
        "n_data_img_path = path.abspath(path.join(parent_dir, 'kaggle_dataset', 'normal'))\n",
        "n_data_save_path = mk_dir(path.join(parent_dir, 'training_crop', 'normal'))"
      ],
      "metadata": {
        "id": "-_9guXIec1Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapt the optic disc segmentation code to current problem\n",
        "def crop_images(parent_dir, data_img_path, data_save_path, data_type='.png', disc_list=[400, 500, 600, 700, 800], \\\n",
        "                DiscROI_size=800, DiscSeg_size=640, CDRSeg_size=400):\n",
        "  \n",
        "  file_test_list = files_with_ext(data_img_path, data_type)\n",
        "\n",
        "  # Load segmentation model\n",
        "  DiscSeg_model = DiscModel.DeepModel(size_set=DiscSeg_size)\n",
        "  DiscSeg_model.load_weights(path.join(parent_dir, 'deep_model', 'Model_DiscSeg_ORIGA.h5'))\n",
        "\n",
        "  for lineIdx, temp_txt in enumerate(file_test_list):\n",
        "\n",
        "      # Show preprocessing progress\n",
        "      print('Processing Img {idx}: {temp_txt}'.format(idx=lineIdx + 1, temp_txt=temp_txt))\n",
        "\n",
        "      # Load image\n",
        "      org_img = np.asarray(image.load_img(path.join(data_img_path, temp_txt)))\n",
        "\n",
        "      # Disc region detection by U-Net\n",
        "      temp_img = resize(org_img, (DiscSeg_size, DiscSeg_size, 3)) * 255\n",
        "      temp_img = np.reshape(temp_img, (1,) + temp_img.shape)\n",
        "      disc_map = DiscSeg_model.predict([temp_img])\n",
        "      disc_map = BW_img(np.reshape(disc_map, (DiscSeg_size, DiscSeg_size)), 0.5)\n",
        "      regions = regionprops(label(disc_map))\n",
        "      C_x = int(regions[0].centroid[0] * org_img.shape[0] / DiscSeg_size)\n",
        "      C_y = int(regions[0].centroid[1] * org_img.shape[1] / DiscSeg_size)\n",
        "\n",
        "      for disc_idx, DiscROI_size in enumerate(disc_list):\n",
        "          disc_region, err_coord, crop_coord = disc_crop(org_img, DiscROI_size, C_x, C_y)\n",
        "          disc_result = Image.fromarray((disc_region).astype(np.uint8))\n",
        "          filename = '{}_{}.png'.format(temp_txt[:-4], DiscROI_size)\n",
        "          disc_result.save(path.join(data_save_path, filename))\n",
        "\n",
        "  plt.imshow(disc_result)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "0f811ZUGcvuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crop_images(parent_dir, g_data_image_path, g_data_save_path, disc_list=[600])\n",
        "crop_images(parent_dir, n_data_image_path, n_data_save_path, disc_list=[600])"
      ],
      "metadata": {
        "id": "X735jtB0dnVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4. References\n",
        "\n",
        "[1] Huazhu Fu, Jun Cheng, Yanwu Xu, Damon Wing Kee Wong, Jiang Liu, and Xiaochun Cao, \"Joint Optic Disc and Cup Segmentation Based on Multi-label Deep Network and Polar Transformation\", IEEE Transactions on Medical Imaging (TMI), vol. 37, no. 7, pp. 1597â€“1605, 2018. [PDF](https://arxiv.org/abs/1801.00926)"
      ],
      "metadata": {
        "id": "wtGJoWTX9odz"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "name": "2-data-splitting-and-augmentation.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}